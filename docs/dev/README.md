[![Version](https://img.shields.io/pypi/v/openpredict)](https://pypi.org/project/openpredict) [![Python versions](https://img.shields.io/pypi/pyversions/openpredict)](https://pypi.org/project/openpredict) [![Run tests](https://github.com/MaastrichtU-IDS/translator-openpredict/workflows/Run%20tests/badge.svg)](https://github.com/MaastrichtU-IDS/translator-openpredict/actions?query=workflow%3A%22Run+tests%22) [![Publish package](https://github.com/MaastrichtU-IDS/translator-openpredict/workflows/Publish%20package/badge.svg)](https://github.com/MaastrichtU-IDS/translator-openpredict/actions?query=workflow%3A%22Publish+package%22) [![SonarCloud Quality Gate Status](https://sonarcloud.io/api/project_badges/measure?project=MaastrichtU-IDS_translator-openpredict&metric=alert_status)](https://sonarcloud.io/dashboard?id=MaastrichtU-IDS_translator-openpredict) [![SonarCloud Maintainability Rating](https://sonarcloud.io/api/project_badges/measure?project=MaastrichtU-IDS_translator-openpredict&metric=sqale_rating)](https://sonarcloud.io/dashboard?id=MaastrichtU-IDS_translator-openpredict) [![SonarCloud Coverage](https://sonarcloud.io/api/project_badges/measure?project=MaastrichtU-IDS_translator-openpredict&metric=coverage)](https://sonarcloud.io/dashboard?id=MaastrichtU-IDS_translator-openpredict)

Additional documentation to develop the **Translator OpenPredict API**.

> Contributions, [feedbacks](https://github.com/MaastrichtU-IDS/translator-openpredict/issues) and pull requests are welcomed!

This repository uses [GitHub Actions](https://github.com/MaastrichtU-IDS/translator-openpredict/actions) to:

* Automatically run tests at each push to the `master` branch
* Publish the [OpenPredict package to PyPI](https://pypi.org/project/openpredict/) when a release is created (N.B.: the version of the package needs to be increased in [setup.py](https://github.com/MaastrichtU-IDS/translator-openpredict/blob/master/setup.py#L6) before).

See [here](https://maastrichtu-ids.github.io/translator-openpredict/docs) to browse the Python code documentation automatically generated by [pydoc-markdown](https://pydoc-markdown.readthedocs.io/en/latest/) ðŸ“–

# Install OpenPredict ðŸ“¥

> Requires [Python 3.6+](https://www.python.org/downloads/) and [pip](https://pip.pypa.io/en/stable/installing/)

Install `openpredict` locally, if you want to run **OpenPredict** in development, make changes to the source code, and build new models.

The **OpenPredict API store its data in a  RDF triplestore**. We use [Ontotext GraphDB](https://github.com/Ontotext-AD/graphdb-docker) at IDS, but you are free to use any other triplestore. You can pass the credentials using environment variables `SPARQL_USER` and `SPARQL_PASSWORD`

### Install from PyPI

Install the latest release published on [PyPI ðŸ·ï¸](https://pypi.org/project/openpredict) (or see below to [run the API with Docker](#option-3-run-with-docker))

```bash
pip3 install openpredict
```

> It is currently recommended to install from the source code to get the latest version

### Install from the source code

Clone this repository:

```bash
git clone https://github.com/MaastrichtU-IDS/translator-openpredict.git
cd translator-openpredict
```

This will install `openpredict` and update the package automatically when the files changes locally ðŸ”ƒ

```bash
pip3 install -e .
```

#### Optional: isolate with a Virtual Environment

If you are facing conflict with already installed packages, then you might want to use a [Virtual Environment](https://docs.python.org/3/tutorial/venv.html) to isolate the installation in the current folder before installing OpenPredict:

```bash
# Create the virtual environment folder in your workspace
python3 -m venv .venv
# Activate it using a script in the created folder
source .venv/bin/activate
```

# Start the OpenPredict API from the source code

### Start the Virtuoso triplestore

Start Virtuoso locally on http://localhost:8890 using Docker (login: `dba` / `dba`)

```bash
docker-compose up -d
```

> Stop the container:
>
> ```bash
> docker-compose down
> ```

### Start the OpenPredict API

Start the OpenPredict API:

```bash
openpredict start-api
```

### Reset your local OpenPredict data

Use the `reset_openpredict.sh` script to delete the folders where the OpenPredict API and Virtuoso data are stored, in `data/virtuoso` and `data/openpredict`

```bash
./reset_openpredict.sh
```

> This command uses `sudo` to be able to delete the `data/virtuoso` folder which has been created by the `docker` user.
>
> On Windows: delete all files in `data` folder, just keep `initial-openpredict-metadata.ttl` 

> See more **[documentation to deploy the OpenPredict API](docs/dev)** locally or with Docker.

# Alternatives to run OpenPredict

See the main README.md if you just want to OpenPredict locally, this documentation is for people who wants to use a specific triplestore, or try out new way to run OpenPredict

### Define environment variables locally

Define the OpenPredict using environment variables for the triplestore credentials in your local terminal. You can also provide the path you want to be used as directory to store models and features files. By default it will do it in a `data` folder in the directory where you started the OpenPredict API.

```bash
export SPARQL_ENDPOINT_URL=https://graphdb.dumontierlab.com/repositories/translator-openpredict-dev
export SPARQL_ENDPOINT_UPDATE_URL=https://graphdb.dumontierlab.com/repositories/translator-openpredict-dev/statements
export SPARQL_USER=import_user
export SPARQL_PASSWORD=password
export OPENPREDICT_APIKEY=myapikey
export OPENPREDICT_DATA_DIR=/data/openpredict
```

> You can add those exports to your `~/.bashrc` or `~/.zshrc` file to define it permanently.

The OpenPredict API can deployed in 3 different ways:

### Option 1: Run from the command line âŒ¨ï¸

Use the `openpredict` CLI to run in development with [Flask ðŸ§ª](https://flask.palletsprojects.com/en/1.1.x/). The API will reload automatically at each change ðŸ”ƒ

```bash
openpredict start-api --debug
```

You can also start the API in production settings using [Tornado ðŸŒªï¸](https://www.tornadoweb.org/en/stable/)

```bash
openpredict start-api
```

> Access the Swagger UI at [http://localhost:8808](http://localhost:8808)

You can provide the API port as argument:

```bash
openpredict start-api --port 8808
```

### Option 2: Run from a Python script ðŸ

```python
from openpredict import openpredict_api

openpredict_api.start_api(8808)
```

> Access the Swagger UI at [http://localhost:8808](http://localhost:8808)

> Run by default in production, set `debug = True` to run in development environments. 

### Option 3: Run with Docker ðŸ³

Running using Docker can be convenient if you just want to run the API without installing the package locally, or if it runs in production alongside other services.

Clone the [repository](https://github.com/MaastrichtU-IDS/translator-openpredict):

```bash
git clone https://github.com/MaastrichtU-IDS/translator-openpredict.git
cd translator-openpredict
```

1. For **development environments**: see above to use the default `docker-compose.yml` file to deploy the Virtuoso triplestore for development using Docker 
2. For **production deployment** use the `docker-compose.prod.yml`

> The docker-compose is currently configured to deploy on [openpredict.semanticscience.org](https://openpredict.semanticscience.org/) using a [nginx-proxy for Docker](https://github.com/nginx-proxy)

Define the triplestore credentials and API key in the `.env` file ðŸ”‘

```bash
nano .env
SPARQL_USER=import_user
SPARQL_PASSWORD=password
```

Start the API in production using GraphDB as backend:

```bash
docker-compose up -f docker-compose.prod.yml up -d
```

> We use a [nginx-proxy for Docker](https://github.com/nginx-proxy/nginx-proxy) and [docker-letsencrypt-nginx-proxy-companion](https://github.com/nginx-proxy/docker-letsencrypt-nginx-proxy-companion) as reverse proxy for HTTP and HTTPS in production. You can change the proxy URL and port via environment variables `VIRTUAL_HOST`, `VIRTUAL_PORT` and `LETSENCRYPT_HOST` in the [docker-compose.yml](https://github.com/MaastrichtU-IDS/translator-openpredict/blob/master/docker-compose.yml) file.

Check the logs:

```bash
docker-compose logs
```

Stop the container:

```bash
docker-compose down
```

# Build the OpenPredict API Docker image

Build and push to the [GitHub Docker Container Registry ðŸ“¦](https://github.com/orgs/MaastrichtU-IDS/packages/container/package/openpredict-api) (make sure the tests passes first!)

```bash
docker build -t ghcr.io/maastrichtu-ids/openpredict-api:latest .
docker push ghcr.io/maastrichtu-ids/openpredict-api:latest
```

# Run tests âœ”ï¸

[![Run tests](https://github.com/MaastrichtU-IDS/translator-openpredict/workflows/Run%20tests/badge.svg)](https://github.com/MaastrichtU-IDS/translator-openpredict/actions?query=workflow%3A%22Run+tests%22)

Tests are automatically run by a [GitHub Action](https://github.com/MaastrichtU-IDS/translator-openpredict/actions?query=workflow%3A%22Run+tests%22) at each push to the `master` branch. They are also run in the GitHub Action to publish a package.

Run the **OpenPredict API** tests locally:

```bash
pytest tests
```

Run a specific test in a file, and display `print` in the output:

```bash
pytest tests/test_openpredict_api.py::test_post_reasoner_predict -s
```

# Create a new API call ðŸ“

Guidelines to create a new API  call in the OpenPredict Open API.

1. Create the operations in the [openpredict/openapi.yml](https://github.com/MaastrichtU-IDS/translator-openpredict/blob/master/openpredict/openapi.yml#L44) file

Provide the path to the function that will resolve this API call:

```yaml
paths:
  /predict:
    get:
      operationId: openpredict.openpredict_api.get_predict
      parameters:
      - name: entity
        in: query
        description: CURIE of the entity to process (e.g. drug, disease, etc)
        example: DRUGBANK:DB00394
        required: true
        schema:
          type: string
```

2. Now, create the function in the [openpredict/openpredict_api.py](https://github.com/MaastrichtU-IDS/translator-openpredict/blob/master/openpredict/openpredict_api.py#L67) file

```python
def get_predict(entity='DB00001'):
    print("Do stuff with " + entity)
```

> The parameters provided in `openapi.yml` and the arguments of the function in `openpredict_api.py` need to match!

# Generate docs ðŸ“–

Documentation in [docs/](docs/)  generated from the Python source code docstrings using [pydoc-markdown](https://pydoc-markdown.readthedocs.io/en/latest/).

```bash
pip3 install pydoc-markdown
```

Generate markdown documentation page for the `openpredict` package in `docs/`

```bash
pydoc-markdown --render-toc -p openpredict > docs/README.md
```

Modify the generated page title:

```bash
find docs/README.md -type f -exec sed -i "s/# Table of Contents/# OpenPredict Package documentation ðŸ”®ðŸ/g" {} +
```

> This can also be done using Sphinx, see this article on [deploying Sphinx to GitHub Pages](https://circleci.com/blog/deploying-documentation-to-github-pages-with-continuous-integration/)
>
> ```bash
> pip3 install sphinx
> sphinx-quickstart sphinx-docs/ --project 'openpredict' --author 'Vincent Emonet'
> cd sphinx-docs/
> make html
> ```

# More about the data model

Metadata about runs, models evaluations, features are stored using the [ML Schema ontology](http://ml-schema.github.io/documentation/ML%20Schema.html) in a RDF triplestore (Ontotext GraphDB).

> See the [ML Schema documentation](http://ml-schema.github.io/documentation/ML%20Schema.html) for more details on the data model.

![OpenPredict datamodel](https://raw.githubusercontent.com/MaastrichtU-IDS/translator-openpredict/master/docs/OpenPREDICT_datamodel.jpg)

