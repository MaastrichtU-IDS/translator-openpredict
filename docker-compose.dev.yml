version: "3"

# Container to develop on remote server with GPUs
services:

  openpredict-dev:
    # image: ghcr.io/vemonet/gpu-workspace:main
    build:
      context: .
      dockerfile: Dockerfile
      args:
        - BASE_IMAGE=ghcr.io/vemonet/gpu-workspace:main
    restart: unless-stopped
    volumes:
      - ./:/app
      - /mnt/um-share-drive/deep-purpose:/shared
    environment:
      - VIRTUAL_HOST=predict-drug-target.137.120.31.160.nip.io
      - LETSENCRYPT_HOST=predict-drug-target.137.120.31.160.nip.io
      # GPU: predict-drug-target.137.120.31.160.nip.io
      # CPU node3: predict-drug-target.137.120.31.148.nip.io
      - VIRTUAL_PORT=8000
      - OPENTELEMETRY_ENABLED=false
      - PYTHONUNBUFFERED=1
      - LOG_LEVEL=INFO
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 3
              capabilities: [gpu]
    shm_size: '4g'
    # ports:
    #   - 8000:8000
    # command: uvicorn --host 0.0.0.0 src.api:app
    entrypoint: bash -c "dvc pull && uvicorn src.trapi_openpredict.main:app --host 0.0.0.0 --port 8000 --log-level debug --reload"
    working_dir: /app/trapi-openpredict
    # --reload
    networks:
      - nginx

# Required to deploy containers publicly
networks:
  nginx:
    name: nginx
    external: true
